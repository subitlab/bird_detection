#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import pandas as pd
from image_utils import compress_image, remove_background, create_final_image
import cv2
import numpy as np
from PIL import Image
import json
from datetime import datetime

class ImageValidator:
    def __init__(self, data_folder='static/', csv_file='all_data.csv'):
        self.data_folder = data_folder
        self.csv_file = csv_file
        self.results = {
            'valid_images': [],
            'invalid_images': [],
            'error_details': {}
        }
    
    def validate_single_image(self, image_path, filepath):
        """éªŒè¯å•ä¸ªå›¾ç‰‡æ˜¯å¦å¯ä»¥æ­£å¸¸å¤„ç†"""
        try:
            print(f"æ­£åœ¨éªŒè¯: {filepath}")
            
            # æ­¥éª¤1: å‹ç¼©å›¾ç‰‡
            compressed_path = compress_image(image_path)
            
            # æ­¥éª¤2: ç§»é™¤èƒŒæ™¯
            image_np, mask = remove_background(compressed_path)
            
            # æ­¥éª¤3: æ£€æŸ¥ä¸»ä½“æ•°é‡ï¼ˆè¿™é‡Œæ˜¯å…³é”®æ£€æŸ¥ç‚¹ï¼‰
            subject_mask = (mask > 0).astype(np.uint8)
            num_labels, labels_im = cv2.connectedComponents(subject_mask)
            num_subjects = num_labels - 1  # å‡å»èƒŒæ™¯
            
            if num_subjects != 1:
                error_msg = f"æœªæ£€æµ‹åˆ°ä¸»ä½“æˆ–æ£€æµ‹åˆ°å¤šä¸ªä¸»ä½“ï¼ˆ{num_subjects} ä¸ªä¸»ä½“ï¼‰"
                print(f"  âŒ {error_msg}")
                self.results['invalid_images'].append(filepath)
                self.results['error_details'][filepath] = {
                    'error': error_msg,
                    'subject_count': num_subjects,
                    'step': 'subject_detection'
                }
                return False
            
            # æ­¥éª¤4: æ£€æŸ¥ä¸»ä½“å°ºå¯¸
            coords = cv2.findNonZero(subject_mask)
            if coords is None:
                error_msg = "æœªæ‰¾åˆ°ä¸»ä½“åæ ‡"
                print(f"  âŒ {error_msg}")
                self.results['invalid_images'].append(filepath)
                self.results['error_details'][filepath] = {
                    'error': error_msg,
                    'subject_count': num_subjects,
                    'step': 'coordinate_detection'
                }
                return False
                
            x, y, w, h = cv2.boundingRect(coords)
            if w < 64 or h < 64:
                error_msg = f"ä¸»ä½“å°ºå¯¸è¿‡å°ï¼ˆ{w}x{h}ï¼‰"
                print(f"  âŒ {error_msg}")
                self.results['invalid_images'].append(filepath)
                self.results['error_details'][filepath] = {
                    'error': error_msg,
                    'subject_count': num_subjects,
                    'dimensions': f"{w}x{h}",
                    'step': 'size_check'
                }
                return False
            
            # å¦‚æœåˆ°è¿™é‡Œï¼Œè¯´æ˜å›¾ç‰‡å¯ä»¥æ­£å¸¸å¤„ç†
            print(f"  âœ… éªŒè¯é€šè¿‡")
            self.results['valid_images'].append(filepath)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(compressed_path):
                os.remove(compressed_path)
            
            return True
            
        except Exception as e:
            error_msg = str(e)
            print(f"  âŒ å¤„ç†å¼‚å¸¸: {error_msg}")
            self.results['invalid_images'].append(filepath)
            self.results['error_details'][filepath] = {
                'error': error_msg,
                'step': 'exception'
            }
            return False
    
    def validate_all_images(self, dataset_filter='test'):
        """éªŒè¯æ‰€æœ‰å›¾ç‰‡"""
        print(f"ğŸ” å¼€å§‹éªŒè¯å›¾ç‰‡ï¼Œæ•°æ®é›†ç­›é€‰: {dataset_filter}")
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        try:
            df = pd.read_csv(self.csv_file)
            print(f"ğŸ“Š ä» {self.csv_file} è¯»å–åˆ° {len(df)} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
            return
        
        # ç­›é€‰æµ‹è¯•é›†æ•°æ®
        if dataset_filter:
            test_images = df[df['data set'] == dataset_filter][['filepaths', 'class']].values.tolist()
            print(f"ğŸ“‹ ç­›é€‰å‡º {len(test_images)} å¼  {dataset_filter} é›†å›¾ç‰‡")
        else:
            test_images = df[['filepaths', 'class']].values.tolist()
            print(f"ğŸ“‹ å¤„ç†æ‰€æœ‰ {len(test_images)} å¼ å›¾ç‰‡")
        
        # éªŒè¯æ¯å¼ å›¾ç‰‡
        total_count = len(test_images)
        valid_count = 0
        invalid_count = 0
        
        for i, (filepath, bird_class) in enumerate(test_images):
            print(f"\n[{i+1}/{total_count}] ", end="")
            
            full_path = os.path.join(self.data_folder, filepath)
            if not os.path.exists(full_path):
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                self.results['invalid_images'].append(filepath)
                self.results['error_details'][filepath] = {
                    'error': 'æ–‡ä»¶ä¸å­˜åœ¨',
                    'step': 'file_check'
                }
                invalid_count += 1
                continue
            
            if self.validate_single_image(full_path, filepath):
                valid_count += 1
            else:
                invalid_count += 1
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        print(f"\n" + "="*50)
        print(f"ğŸ“Š éªŒè¯å®Œæˆï¼")
        print(f"âœ… æœ‰æ•ˆå›¾ç‰‡: {valid_count} å¼ ")
        print(f"âŒ æ— æ•ˆå›¾ç‰‡: {invalid_count} å¼ ")
        print(f"ğŸ“ˆ æœ‰æ•ˆç‡: {valid_count/total_count*100:.1f}%")
        
        return self.results
    
    def save_results(self, output_file='image_validation_results.json'):
        """ä¿å­˜éªŒè¯ç»“æœåˆ°æ–‡ä»¶"""
        result_data = {
            'timestamp': datetime.now().isoformat(),
            'total_images': len(self.results['valid_images']) + len(self.results['invalid_images']),
            'valid_count': len(self.results['valid_images']),
            'invalid_count': len(self.results['invalid_images']),
            'valid_images': self.results['valid_images'],
            'invalid_images': self.results['invalid_images'],
            'error_details': self.results['error_details']
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # åŒæ—¶ä¿å­˜æ— æ•ˆå›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºåç»­ç­›é€‰ï¼‰
        invalid_list_file = 'invalid_images_list.txt'
        with open(invalid_list_file, 'w', encoding='utf-8') as f:
            for filepath in self.results['invalid_images']:
                f.write(f"{filepath}\n")
        
        print(f"ğŸ“ æ— æ•ˆå›¾ç‰‡åˆ—è¡¨å·²ä¿å­˜åˆ°: {invalid_list_file}")
    
    def generate_report(self):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        print(f"\n" + "="*60)
        print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯æŠ¥å‘Š")
        print(f"="*60)
        
        # æŒ‰é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_types = {}
        for filepath, details in self.results['error_details'].items():
            error = details['error']
            if error not in error_types:
                error_types[error] = []
            error_types[error].append(filepath)
        
        for error_type, files in error_types.items():
            print(f"\nğŸ”¸ {error_type}: {len(files)} å¼ å›¾ç‰‡")
            for filepath in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªä¾‹å­
                print(f"   - {filepath}")
            if len(files) > 5:
                print(f"   ... è¿˜æœ‰ {len(files) - 5} å¼ å›¾ç‰‡")

def main():
    print("ğŸ¯ å¼€å§‹å›¾ç‰‡éªŒè¯ä»»åŠ¡")
    
    validator = ImageValidator()
    
    # éªŒè¯æ‰€æœ‰å›¾ç‰‡
    results = validator.validate_all_images(dataset_filter='test')
    
    # ä¿å­˜ç»“æœ
    validator.save_results()
    
    # ç”ŸæˆæŠ¥å‘Š
    validator.generate_report()
    
    print(f"\nâœ… éªŒè¯ä»»åŠ¡å®Œæˆï¼")
    print(f"ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥ä½¿ç”¨ç”Ÿæˆçš„ 'invalid_images_list.txt' æ–‡ä»¶æ¥è¿‡æ»¤ç…§ç‰‡å¢™ä¸­çš„é—®é¢˜å›¾ç‰‡")

if __name__ == "__main__":
    main() 