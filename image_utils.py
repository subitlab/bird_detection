import cv2
import numpy as np
from torchvision import models, transforms
import torch
from PIL import Image
import os
import random
import string

# ç¡®å®šè®¡ç®—è®¾å¤‡
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åŠ è½½åˆ†å‰²æ¨¡å‹
def load_segmentation_model():
    model = models.segmentation.deeplabv3_resnet101(pretrained=True)
    model.to(DEVICE)
    model.eval()
    return model

segmentation_model = load_segmentation_model()

# ç”Ÿæˆéšæœºæ–‡ä»¶åçš„å‡½æ•°
def generate_random_filename(extension):
    random_str = ''.join(random.choices(string.ascii_letters + string.digits, k=16))
    return f"{random_str}.{extension}"

def compress_image(image_path, output_folder="uploads"):
    image = Image.open(image_path).convert("RGB")
    orig_w, orig_h = image.size
    scale = min(1024 / orig_w, 1024 / orig_h)
    new_w = int(orig_w * scale)
    new_h = int(orig_h * scale)
    image_resized = image.resize((new_w, new_h), Image.Resampling.LANCZOS)

    background = Image.new("RGB", (1024, 1024), (255, 255, 255))
    x_offset = (1024 - new_w) // 2
    y_offset = (1024 - new_h) // 2
    background.paste(image_resized, (x_offset, y_offset))

    os.makedirs(output_folder, exist_ok=True)
    output_filename = generate_random_filename("jpg")
    output_path = os.path.join(output_folder, output_filename)
    background.save(output_path, quality=85)
    return output_path

# å›¾ç‰‡é¢„å¤„ç†
def preprocess(image):
    preprocess_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    return preprocess_transform(image).unsqueeze(0).to(DEVICE)

# åˆ†å‰²èƒŒæ™¯
def remove_background(image_path):
    image = Image.open(image_path).convert("RGB")
    input_tensor = preprocess(image)
    
    with torch.no_grad():
        output = segmentation_model(input_tensor)["out"][0]
    # å°†è¾“å‡ºä¸Šé‡‡æ ·åˆ°è¾“å…¥å›¾åƒå¤§å°
    output = torch.nn.functional.interpolate(
        output.unsqueeze(0),
        size=image.size[::-1],
        mode='bilinear',
        align_corners=False
    )[0]
    mask = output.argmax(0).byte().cpu().numpy()
    
    image_np = np.array(image)
    return image_np, mask

# åˆ›å»ºæœ€ç»ˆå›¾åƒ
def create_final_image(image_np, mask, output_folder="uploads"):
    # è¯†åˆ«ä¸»ä½“éƒ¨åˆ†
    subject_mask = (mask > 0).astype(np.uint8)
    
    # å½¢æ€å­¦æ“ä½œæ¸…ç†æ©è†œ
    # 1. å¼€è¿ç®—ï¼šå»é™¤å°å™ªå£°
    kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    subject_mask = cv2.morphologyEx(subject_mask, cv2.MORPH_OPEN, kernel_small)
    
    # 2. é—­è¿ç®—ï¼šè¿æ¥æ–­å¼€çš„åŒºåŸŸ
    kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    subject_mask = cv2.morphologyEx(subject_mask, cv2.MORPH_CLOSE, kernel_large)
    
    # æŸ¥æ‰¾è¿æ¥çš„ç»„ä»¶ï¼ˆä¸»ä½“ï¼‰
    num_labels, labels_im = cv2.connectedComponents(subject_mask)
    num_subjects = num_labels - 1  # å‡å»èƒŒæ™¯
    
    if num_subjects == 0:
        raise Exception(f"æœªæ£€æµ‹åˆ°ä»»ä½•ä¸»ä½“")
    elif num_subjects == 1:
        # åªæœ‰ä¸€ä¸ªä¸»ä½“ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
        coords = cv2.findNonZero(subject_mask)
        x, y, w, h = cv2.boundingRect(coords)
    else:
        # å¤šä¸ªä¸»ä½“æ—¶ï¼Œé€‰æ‹©æœ€ä½³çš„ä¸»ä½“
        print(f"ğŸ” æ£€æµ‹åˆ° {num_subjects} ä¸ªä¸»ä½“ï¼Œæ™ºèƒ½é€‰æ‹©æœ€ä½³ä¸»ä½“")
        
        best_score = 0
        best_component = 0
        image_center_x, image_center_y = image_np.shape[1] // 2, image_np.shape[0] // 2
        
        # éå†æ‰€æœ‰è¿é€šç»„ä»¶ï¼Œè®¡ç®—ç»¼åˆè¯„åˆ†
        for label in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯ï¼ˆlabel=0ï¼‰
            component_mask = (labels_im == label).astype(np.uint8)
            area = cv2.countNonZero(component_mask)
            
            # è·³è¿‡è¿‡å°çš„ç»„ä»¶
            if area < 100:  # è¿‡æ»¤æ‰å™ªå£°ç‚¹
                continue
            
            # è·å–ç»„ä»¶çš„è¾¹ç•Œæ¡†å’Œä¸­å¿ƒç‚¹
            coords = cv2.findNonZero(component_mask)
            if coords is None:
                continue
                
            x, y, w, h = cv2.boundingRect(coords)
            component_center_x = x + w // 2
            component_center_y = y + h // 2
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            # 1. é¢ç§¯è¯„åˆ† (40%)
            area_score = area / (image_np.shape[0] * image_np.shape[1])  # å½’ä¸€åŒ–é¢ç§¯
            
            # 2. ä½ç½®è¯„åˆ† (30%) - è¶Šé è¿‘å›¾åƒä¸­å¿ƒè¶Šå¥½
            distance_to_center = np.sqrt((component_center_x - image_center_x)**2 + 
                                       (component_center_y - image_center_y)**2)
            max_distance = np.sqrt(image_center_x**2 + image_center_y**2)
            position_score = 1 - (distance_to_center / max_distance)
            
            # 3. å½¢çŠ¶è¯„åˆ† (20%) - é•¿å®½æ¯”æ¥è¿‘1:1åˆ°2:1ä¹‹é—´è¾ƒå¥½ï¼ˆé¸Ÿç±»ç‰¹å¾ï¼‰
            aspect_ratio = max(w, h) / min(w, h)
            if aspect_ratio <= 2.0:
                shape_score = 1.0
            elif aspect_ratio <= 3.0:
                shape_score = 0.7
            else:
                shape_score = 0.3
            
            # 4. å°ºå¯¸è¯„åˆ† (10%) - ä¸èƒ½å¤ªå°ä¹Ÿä¸èƒ½å¤ªå¤§
            size_ratio = min(w, h) / max(image_np.shape[0], image_np.shape[1])
            if 0.1 <= size_ratio <= 0.8:
                size_score = 1.0
            else:
                size_score = 0.5
            
            # ç»¼åˆè¯„åˆ†
            total_score = (area_score * 0.6 + position_score * 0.1 + 
                          shape_score * 0.1 + size_score * 0.1)
            
            print(f"  ç»„ä»¶ {label}: é¢ç§¯={area}, ä½ç½®=({component_center_x},{component_center_y}), "
                  f"å°ºå¯¸={w}x{h}, è¯„åˆ†={total_score:.3f}")
            
            if total_score > best_score:
                best_score = total_score
                best_component = label
        
        if best_component == 0:
            raise Exception(f"æœªæ‰¾åˆ°åˆé€‚çš„ä¸»ä½“ç»„ä»¶")
        
        # åˆ›å»ºåªåŒ…å«æœ€ä½³ä¸»ä½“çš„æ©è†œ
        subject_mask = (labels_im == best_component).astype(np.uint8)
        coords = cv2.findNonZero(subject_mask)
        
        if coords is None:
            raise Exception(f"æ— æ³•æ‰¾åˆ°æœ€ä½³ä¸»ä½“çš„åæ ‡")
            
        x, y, w, h = cv2.boundingRect(coords)
        print(f"âœ… é€‰æ‹©äº†è¯„åˆ†æœ€é«˜çš„ä¸»ä½“ (è¯„åˆ†: {best_score:.3f}, å°ºå¯¸: {w}x{h})")
    
    # æ£€æŸ¥ä¸»ä½“å°ºå¯¸
    if w < 64 or h < 64:
        raise Exception(f"ä¸»ä½“å°ºå¯¸è¿‡å°ï¼ˆ{w}x{h}ï¼‰")
    
    # æå–ä¸»ä½“å’Œæ©è†œ
    subject = image_np[y:y+h, x:x+w]
    subject_mask = subject_mask[y:y+h, x:x+w]
    
    # ä¿æŒé•¿å®½æ¯”è°ƒæ•´ä¸»ä½“å°ºå¯¸åˆ°é€‚åˆ 224x224
    subject_h, subject_w = subject.shape[:2]
    scale = min(224 / subject_w, 224 / subject_h)
    new_w = int(subject_w * scale)
    new_h = int(subject_h * scale)
    subject_resized = cv2.resize(subject, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    mask_resized = cv2.resize(subject_mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
    mask_resized = mask_resized.astype(bool)
    
    # åˆ›å»ºéšæœºå™ªå£°èƒŒæ™¯
    final_image = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
    
    # è®¡ç®—ä¸»ä½“åœ¨èƒŒæ™¯ä¸­çš„ä½ç½®ï¼Œä½¿å…¶å±…ä¸­
    x_offset = (224 - new_w) // 2
    y_offset = (224 - new_h) // 2
    
    # åˆæˆæœ€ç»ˆå›¾åƒ
    roi = final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w]
    roi[mask_resized] = subject_resized[mask_resized]
    final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = roi
    
    # å°†å›¾åƒä»BGRè½¬æ¢ä¸ºRGB
    final_image_rgb = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)
    final_image_pil = Image.fromarray(final_image_rgb)

    os.makedirs(output_folder, exist_ok=True)
    output_filename = generate_random_filename("jpg")
    output_path = os.path.join(output_folder, output_filename)
    final_image_pil.save(output_path)
    return output_path